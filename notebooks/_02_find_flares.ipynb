{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "UTF-8, Python 3\n",
    "\n",
    "------------------\n",
    "Flaring SPI\n",
    "------------------\n",
    "\n",
    "Ekaterina Ilin, 2021, MIT License\n",
    "\n",
    "De-trending Kepler and TESS\n",
    "\n",
    "- get table of Kepler exoplanet system light curves\n",
    "- fetch FLC\n",
    "- get system info from table\n",
    "- mask transits\n",
    "- apply custom detrending\n",
    "- search flares\n",
    "- save results\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from funcs.notebook import *\n",
    "from funcs.detrend import estimate_detrended_noise, fit_spline, remove_sines_iteratively, remove_exponential_fringes\n",
    "from funcs.transitmask import get_full_transit_mask\n",
    "\n",
    "from altaipony.lcio import from_mast, from_path\n",
    "from altaipony.flarelc import FlareLightCurve\n",
    "from altaipony.altai import find_iterative_median\n",
    "\n",
    "from lightkurve import search_lightcurvefile\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "\n",
    "def custom_detrending(lc, spline_coarseness=30, spline_order=3,\n",
    "                      savgol1=6., savgol2=3., pad=3):\n",
    "    \"\"\"Custom de-trending for TESS and Kepler \n",
    "    short cadence light curves, including TESS Cycle 3 20s\n",
    "    cadence.\n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    lc : FlareLightCurve\n",
    "        light curve that has at least time, flux and flux_err\n",
    "    spline_coarseness : float\n",
    "        time scale in hours for spline points. \n",
    "        See fit_spline for details.\n",
    "    spline_order: int\n",
    "        Spline order for the coarse spline fit.\n",
    "        Default is cubic spline.\n",
    "    savgol1 : float\n",
    "        Window size for first Savitzky-Golay filter application.\n",
    "        Unit is hours, defaults to 6 hours.\n",
    "    savgol2 : float\n",
    "        Window size for second Savitzky-Golay filter application.\n",
    "        Unit is hours, defaults to 3 hours.\n",
    "    pad : 3\n",
    "        Outliers in Savitzky-Golay filter are padded with this\n",
    "        number of data points. Defaults to 3.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    FlareLightCurve with detrended_flux attribute\n",
    "    \"\"\"\n",
    "    dt = np.mean(np.diff(lc.time.value))\n",
    "\n",
    "    # fit a spline to the general trends\n",
    "    lc1, model = fit_spline(lc, spline_order=spline_order,\n",
    "                            spline_coarseness=spline_coarseness)\n",
    "    \n",
    "    # replace for next step\n",
    "    lc1.flux = lc1.detrended_flux.value\n",
    "\n",
    "    # removes strong and fast variability on 5 day to 4.8 hours \n",
    "    # simple sines are probably because rotational variability is \n",
    "    # either weak and transient or strong and persistent on the timescales\n",
    "    lc2 = remove_sines_iteratively(lc1)\n",
    "    \n",
    "    # choose a 6 hour window\n",
    "    w = int((np.rint(savgol1 / 24. / dt) // 2) * 2 + 1)\n",
    "\n",
    "    # use Savitzy-Golay to iron out the rest\n",
    "    lc3 = lc2.detrend(\"savgol\", window_length=w, pad=pad)\n",
    "\n",
    "    # choose a three hour window\n",
    "    w = int((np.rint(savgol2 / 24. / dt) // 2) * 2 + 1)\n",
    "\n",
    "    # use Savitzy-Golay to iron out the rest\n",
    "    lc4 = lc3.detrend(\"savgol\", window_length=w, pad=pad)\n",
    "\n",
    "    # find median value\n",
    "    lc4 = find_iterative_median(lc4)\n",
    "\n",
    "    # replace for next step\n",
    "    lc4.flux = lc4.detrended_flux.value\n",
    "    \n",
    "    # remove exopential fringes that neither spline, \n",
    "    # nor sines, nor SavGol can remove.\n",
    "    lc5 = remove_exponential_fringes(lc4)\n",
    "  \n",
    "    return lc5\n",
    "\n",
    "\n",
    "def add_meta_data_and_write(ff, dflcn, ID, TIC, sector, mission,\n",
    "                  lc_n, w, tstamp, mask_pos_outliers_sigma):\n",
    "    \"\"\"Write out flare table to file.\"\"\"\n",
    "    \n",
    "    \n",
    "    if ff.shape[0]==0:\n",
    "        ff[\"phase\"]=-1\n",
    "        ff[\"total_n_valid_data_points\"] = dflcn.detrended_flux.shape[0]\n",
    "        ff[\"ID\"] = ID\n",
    "        ff[\"TIC\"] = TIC\n",
    "        ff[\"qcs\"] = sector\n",
    "        ff[\"mission\"] = mission\n",
    "        ff[\"tstamp\"] = tstamp\n",
    "        ff[\"lc_n\"] = lc_n\n",
    "        ff[\"w\"] = w\n",
    "        ff[\"mask_pos_outliers_sigma\"] = mask_pos_outliers_sigma\n",
    "        ff[\"real\"]=-1\n",
    "        ff = ff.append({\"phase\":-1,\n",
    "                        \"total_n_valid_data_points\":dflcn.detrended_flux.shape[0],\n",
    "                        \"ID\":ID,\n",
    "                        \"TIC\":TIC,\n",
    "                        \"qcs\" : sector,\n",
    "                        \"mission\":mission,\n",
    "                        \"tstamp\":tstamp,\n",
    "                        \"lc_n\":lc_n,\n",
    "                        \"w\":w,\n",
    "                        \"mask_pos_outliers_sigma\":mask_pos_outliers_sigma,\n",
    "                        \"real\":-1},\n",
    "                         ignore_index=True)\n",
    "\n",
    "    # otherwise add ID, QCS and mission\n",
    "    else:\n",
    "        ff[\"total_n_valid_data_points\"] = dflcn.detrended_flux.shape[0]\n",
    "        ff[\"ID\"] = ID\n",
    "        ff[\"TIC\"] = TIC\n",
    "        ff[\"qcs\"] = sector\n",
    "        ff[\"mission\"] = mission\n",
    "        ff[\"tstamp\"] = tstamp\n",
    "        ff[\"lc_n\"] = lc_n\n",
    "        ff[\"w\"] = w\n",
    "        ff[\"mask_pos_outliers_sigma\"] = mask_pos_outliers_sigma\n",
    "\n",
    "    # add results to file\n",
    "    with open(\"../results/2022_07_flares.csv\", \"a\") as file:\n",
    "        ff.to_csv(file, index=False, header=False)\n",
    "            \n",
    "def write_flc_to_file(dflcn, flc, path_dflcn):\n",
    "    \"\"\"Write detrended light curve to fits.\"\"\"\n",
    "    \n",
    "    \n",
    "    dflcn.to_fits(path_dflcn, \n",
    "                  FLUX=flc.flux.value,\n",
    "                  DETRENDED_FLUX=dflcn.detrended_flux.value,\n",
    "                  DETRENDED_FLUX_ERR=dflcn.detrended_flux_err.value,\n",
    "                  IT_MED=dflcn.it_med.value,\n",
    "                  FLUX_MODEL=dflcn.flux_model.value,\n",
    "                  PHASE = dflcn.phase,\n",
    "                  overwrite=True)\n",
    "\n",
    "def write_no_lc(input_target):\n",
    "    with open(\"../results/2022_07_nolc.txt\",\"a\") as f:\n",
    "        s = f\"TIC {input_target.TIC}\\n\"\n",
    "        f.write(s)\n",
    "    \n",
    "    \n",
    "sep = \"-----------------------------------------\"\n",
    "\n",
    "def mprint(message):\n",
    "    print(sep)\n",
    "    print(message)\n",
    "    print(sep)\n",
    "    \n",
    "offset = {\"K2\":2454833.,\n",
    "          \"Kepler\":2454833.,\n",
    "          \"TESS\":2457000.,\n",
    "          'Transiting Exoplanet Survey Satellite (TESS)':2457000.}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(flc, input_target, sector, mission, lc_n, download_dir,\n",
    "                 i=0, mask_pos_outliers_sigma = 2.5, addtail = True):\n",
    "    # get timestamp for result\n",
    "    tstamp = time.strftime(\"%Y_%m_%d\", time.localtime())\n",
    "    print(f\"date: {tstamp}\")\n",
    "\n",
    "    dflc = custom_detrending(flc)\n",
    "    print(\"LC successfully detrended.\")\n",
    "\n",
    "    # define two hour window for rolling std\n",
    "    w = np.floor(1. / 12. / np.nanmin(np.diff(dflc.time.value)))\n",
    "    if w%2==0: \n",
    "        w+=1\n",
    "\n",
    "    # use window to estimate the noise in the LC\n",
    "    dflcn = estimate_detrended_noise(dflc, std_window=int(w), \n",
    "                                  mask_pos_outliers_sigma=mask_pos_outliers_sigma)\n",
    "\n",
    "    # search the residual for flares\n",
    "    ff = dflcn.find_flares(addtail=addtail).flares\n",
    "\n",
    "\n",
    "    # calculate the observed phases\n",
    "    # calculate midtime of transit in TESS or Kepler time\n",
    "    if mission == \"TESS\":\n",
    "        if np.isfinite(input_target.pl_tranmid_tess):\n",
    "            midtime = input_target.pl_tranmid_tess - offset[mission]\n",
    "        else:\n",
    "            midtime = input_target.pl_tranmid - offset[mission]\n",
    "    elif mission == \"Kepler\":\n",
    "        midtime = input_target.pl_tranmid - offset[mission]\n",
    "    print(f\"Transit midtime in {mission} time: {midtime}\")\n",
    "\n",
    "    # calculate phases for the light curve\n",
    "    dflcn['phase'] = ((dflcn.time.value - midtime) % input_target.pl_orbper) / input_target.pl_orbper\n",
    "\n",
    "    # calculate the phase at which the flare was observed\n",
    "    ff[\"phase\"] = ff.cstart.apply(lambda x: dflcn[\"phase\"][np.where(x==dflcn.cadenceno)][0])\n",
    "    \n",
    "\n",
    "    # this is just to get the order of columns right, will be added later again\n",
    "    if ff.shape[0]>0:\n",
    "        del ff[\"total_n_valid_data_points\"]\n",
    "\n",
    "    # chop out all phases where we have no data points to look for flares in:\n",
    "    dflcn[\"phase\"][~np.isfinite(dflcn[\"detrended_flux\"])] = np.nan\n",
    "\n",
    "    fshow = ff[[\"tstart\",'tstop',\"phase\",\"ampl_rec\",\"dur\"]]\n",
    "    if fshow.shape[0]>0:\n",
    "        print(f\"Flares found:\\n{fshow}\")\n",
    "    else:\n",
    "        print(f'No flares found in LC.')\n",
    "\n",
    "    # add meta info to flare table\n",
    "    # if no flares found, add empty row and write to file\n",
    "    add_meta_data_and_write(ff, dflcn, input_target.hostname, \n",
    "                            input_target.TIC, sector,\n",
    "                            mission, lc_n, w, tstamp,\n",
    "                            mask_pos_outliers_sigma)\n",
    "\n",
    "\n",
    "    #write out detrended light curve\n",
    "    if mission==\"TESS\":\n",
    "        path_dflcn = f\"{download_dir}/{tstamp}_{input_target.TIC}_{sector}_altai_{i}.fits\"\n",
    "    elif mission==\"Kepler\":\n",
    "        name = input_target.hostname.replace(\" \",\"_\").replace(\"-\",\"_\")\n",
    "        path_dflcn = f\"{download_dir}/{tstamp}_{input_target.hostname}_{sector}_altai_{i}.fits\"\n",
    "        \n",
    "    write_flc_to_file(dflcn, flc, path_dflcn)\n",
    "    print(f\"Wrote out LC to {path_dflcn}.\")\n",
    "\n",
    "    return ff.shape[0]\n",
    "\n",
    "def get_table_of_light_curves(input_target):\n",
    "\n",
    "    try:\n",
    "        lcs  = search_lightcurvefile(input_target.hostname)   \n",
    "        conditions = (lcs.exptime.value < 130) & (lcs.author != \"TASOC\")\n",
    "        lcs_sel = lcs[conditions]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            lcs  = search_lightcurvefile(f\"TIC {input_target.TIC}\")\n",
    "            conditions = (lcs.exptime.value < 130) & (lcs.author != \"TASOC\")\n",
    "            lcs_sel = lcs[conditions]\n",
    "        except KeyError:\n",
    "            write_no_lc(input_target)\n",
    "            return\n",
    "    if len(lcs_sel)==0:\n",
    "        write_no_lc(input_target)\n",
    "        return\n",
    "   \n",
    "    \n",
    "    lcs_sel = lcs_sel.table.to_pandas().sort_values(by=\"t_exptime\")\n",
    "    lcs_sel_tess = lcs_sel.loc[lcs_sel.mission.str[:4]==\"TESS\",:].drop_duplicates(subset=[\"mission\"],keep=\"first\")\n",
    "    lcs_sel_kepler = lcs_sel[lcs_sel.mission.str[:6]==\"Kepler\"].drop_duplicates(subset=[\"mission\"])\n",
    "\n",
    "    lcs_sel = pd.concat([lcs_sel_kepler,lcs_sel_tess])\n",
    "   \n",
    "    return lcs_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite Table of confirmed exoplanets\n",
    "path = \"../data/2022_07_27_input_catalog_star_planet_systems.csv\"\n",
    "\n",
    "mprint(f\"[UP] Using compiled input catalog from {path}\")\n",
    "\n",
    "input_catalog = pd.read_csv(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs_sel=pd.DataFrame()\n",
    "lcs_sel.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_catalog[input_catalog.hostname == \"Kepler-1313\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "#Kepler-24 is the next one in line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Nflares = 0 \n",
    "while Nflares < 1000:\n",
    "    print(f\"\\nCOUNT: {count}\\n\")\n",
    "    lcs_sel=pd.DataFrame()\n",
    "    print(lcs_sel.shape)\n",
    "    while lcs_sel.shape[0]==0:\n",
    "        input_target = input_catalog.iloc[count]\n",
    "\n",
    "        lcs_sel = get_table_of_light_curves(input_target)\n",
    "        if lcs_sel is None:\n",
    "            lcs_sel=pd.DataFrame()\n",
    "        count+=1\n",
    "\n",
    "    TIC = \"TIC \" + str(input_target.TIC)\n",
    "    ID = input_target.hostname\n",
    "    n = 0\n",
    "    Nflares = 0\n",
    "    while n<lcs_sel.shape[0]:\n",
    "\n",
    "        sector = lcs_sel.iloc[n].mission[-2:]\n",
    "        mission = lcs_sel.iloc[n].mission.split(\" \")[0]\n",
    "\n",
    "        lc_n = n + 1\n",
    "\n",
    "        if lcs_sel.iloc[n].exptime < 30:\n",
    "            cadence = \"fast\"\n",
    "        else: \n",
    "            cadence = \"short\"\n",
    "\n",
    "        print(f\"Get {mission} Sector/Quarter {sector}, {TIC}, {ID}, {cadence} cadence.\")\n",
    "\n",
    "        # fetch light curve from MAST\n",
    "        download_dir = \"/home/ekaterina/Documents/001_science/lcs\"\n",
    "\n",
    "        if mission==\"TESS\":\n",
    "            flc = from_mast(TIC, mission=mission, c=sector,\n",
    "                        cadence=cadence, author=\"SPOC\",\n",
    "                        download_dir=download_dir)\n",
    "            if flc is None:\n",
    "                print(f\"No LC found for {mission}, {ID}, Quarter {sector}.\")\n",
    "                with open(\"../results/2022_07_listed_but_nothing_found.txt\", \"a\") as f:\n",
    "                    string = f\"{mission},{ID},{TIC},{sector},{cadence}\\n\"\n",
    "                    f.write(string)\n",
    "                n += 1\n",
    "            else:\n",
    "                Nflares += run_analysis(flc, input_target, sector, mission, lc_n, download_dir, i=0)\n",
    "                n += 1\n",
    "        elif mission==\"Kepler\":\n",
    "            flcl = from_mast(ID, mission=mission, c=sector,\n",
    "                        cadence=cadence,\n",
    "                        download_dir=download_dir)\n",
    "\n",
    "            if flcl is None:\n",
    "                print(f\"No LC found for {mission}, {ID}, Quarter {sector}.\")\n",
    "                with open(\"../results/2022_07_listed_but_nothing_found.txt\", \"a\") as f:\n",
    "                    string = f\"{mission},{ID},{TIC},{sector},{cadence}\\n\"\n",
    "                    f.write(string)\n",
    "                n += 1\n",
    "\n",
    "            elif type(flcl) != list:\n",
    "\n",
    "                print(f\"1 LC found for {mission}, {ID}, Quarter {sector}.\")\n",
    "                Nflares += run_analysis(flcl, input_target, sector, mission, lc_n, download_dir, i=0)\n",
    "                n += 1\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(f\"{len(flcl)} LCs found for {mission}, {ID}, Quarter {sector}.\")\n",
    "                for i, flc in enumerate(flcl):\n",
    "                    Nflares += run_analysis(flc, input_target, sector, mission, lc_n, download_dir, i=i)\n",
    "\n",
    "                n += 1\n",
    "\n",
    "    print(f\"\\n---------------------\\n{Nflares} flares found!\\n-------------------\\n\")\n",
    "print(f\"\\nNext count is {count}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(flcl) != list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022_07_29_Kepler-974_14_altai_2\n",
    "# 2022_07_29_Kepler-974_15_altai_2\n",
    "# 2022_07_29_Kepler-974_16_altai_1.fits +2\n",
    "fff = fits.open(\"/home/ekaterina/Documents/001_science/lcs/2022_07_29_Kepler-350_14_altai_2.fits\")[1].data\n",
    "ff = pd.read_csv(\"../results/2022_07_flares.csv\")\n",
    "ff = ff[(ff.ID == ID) & (ff.qcs==14)]\n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for j, flare in ff.iloc[2:].iterrows():\n",
    "    plt.figure(figsize=(16,5))\n",
    "    cap=.5\n",
    "    ts, tf = flare.tstart, flare.tstop\n",
    "    print(ts,tf)\n",
    "    _ = fff[np.where((fff['time']>=ts-.1/cap) & (fff['time']<=tf+.1/cap))]\n",
    "    med = np.median(_['flux'])\n",
    "    plt.plot(_['time'], _['flux']/med, c=\"k\")\n",
    "    \n",
    "    _ = fff[np.where((fff['time']>=ts-1e-8) & (fff['time']<=tf+1e-8))]\n",
    "    plt.scatter(_['time'], _['flux']/med, c=\"r\")\n",
    "\n",
    "    plt.scatter(ts, flare.phase/5 + 1)\n",
    "    plt.plot(_['time'], _['phase']/5 + 1, c=\"grey\")\n",
    "#     plt.ylim(0.99,1.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
