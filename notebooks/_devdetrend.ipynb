{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "UTF-8, Python 3\n",
    "\n",
    "------------------\n",
    "Flaring SPI\n",
    "------------------\n",
    "\n",
    "Ekaterina Ilin, 2021, MIT License\n",
    "\n",
    "De-trending Kepler and TESS\n",
    "\n",
    "- get table of Kepler exoplanet system light curves\n",
    "- fetch FLC\n",
    "- get system info from table\n",
    "- mask transits\n",
    "- apply custom detrending\n",
    "- search flares\n",
    "- save results\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from funcs.notebook import *\n",
    "from funcs.detrend import estimate_detrended_noise, custom_detrending\n",
    "from funcs.transitmask import get_full_transit_mask\n",
    "\n",
    "from altaipony.lcio import from_mast\n",
    "from altaipony.flarelc import FlareLightCurve\n",
    "\n",
    "\n",
    "sep = \"-----------------------------------------\"\n",
    "\n",
    "def mprint(message):\n",
    "    print(sep)\n",
    "    print(message)\n",
    "    print(sep)\n",
    "    \n",
    "offset = {\"K2\":2454833.,\"Kepler\":2454833.,\"TESS\":2457000.}    \n",
    "\n",
    "\n",
    "\n",
    "# Composite Table of confirmed exoplanets\n",
    "path = \"20_01_2021_confirmed_uncontroversial_exoplanet_systems.csv\"\n",
    "\n",
    "mprint(f\"[UP] Using confirmed and uncontroversial \"\n",
    "      \"entries in NASA Composite Table from {path}\")\n",
    "\n",
    "exokepler = pd.read_csv(f\"../data/{path}\") # composite table\n",
    "\n",
    "# read in TESS-TOI sample \n",
    "path = \"../data/2021_01_13_TESS_TOI_CATALOG.csv\"\n",
    "\n",
    "mprint(f\"[UP] Using TESS-TOI Table from {path}\")\n",
    "\n",
    "exotess = pd.read_csv(path, skiprows=4)\n",
    "\n",
    "# rename the relevant columns for transit masking\n",
    "exotess = exotess.rename(index=str, \n",
    "                         columns={'Transit Duration Value':\"pl_trandur\",\n",
    "                                  'Orbital Period Value': \"pl_orbper\", \n",
    "                                  'Epoch Value':\"pl_tranmidepoch\"})\n",
    "\n",
    "\n",
    "# read in list of LCs to search\n",
    "es = pd.read_csv(\"../data/20_01_2021_full_kepler_k2_tess_exoplanet_lcs_some_excluded.csv\")\n",
    "\n",
    "# select only Kepler and TESS, ignore K2 for now\n",
    "eskeptess = es[(es.mission==\"TESS\") | (es.mission==\"Kepler\")]\n",
    "\n",
    "\n",
    "#work through a subset first\n",
    "# eskeptess = eskeptess.iloc[[471]]\n",
    "eskeptess = eskeptess[(eskeptess.ID == \"AU Mic\") & (eskeptess.qcs == 27)]\n",
    "\n",
    "#track progress\n",
    "N, n = eskeptess.shape[0], 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in eskeptess.iterrows():\n",
    "\n",
    "    # Get system info: all planet, any transits\n",
    "    if row.mission == \"TESS\":\n",
    "        # TIC is unique ID for star\n",
    "        system = exotess[(exotess.TIC == row.TIC)]\n",
    "\n",
    "    elif row.mission == \"Kepler\":\n",
    "        # ID is unique, also ignore entries that have no transits\n",
    "        # because there is nothing to mask (they are still searched for flares)\n",
    "        system = exokepler[(exokepler.hostname == row.ID) &\n",
    "                           (exokepler.discoverymethod == \"Transit\")]\n",
    "        if system.shape[0] > 0:\n",
    "            system[\"pl_tranmidepoch\"] = system.pl_tranmid - offset[system.iloc[0].disc_facility]\n",
    "\n",
    "    # fetch light curve from MAST\n",
    "    flc = from_mast(row.ID, mission=row.mission, c=row.qcs, cadence=\"short\", \n",
    "                    download_dir=\"/media/ekaterina/40A2-49D9/lcs\")\n",
    "\n",
    "    # make it a list of LCs even if only one LC is returned\n",
    "    if type(flc) == FlareLightCurve:\n",
    "\n",
    "        flc = [flc]\n",
    "\n",
    "    elif type(flc) == list:\n",
    "\n",
    "        flc = flc\n",
    "\n",
    "    # info\n",
    "    mprint(f\"{len(flc)} light curves available for {row.ID} in {row.mission}.\")\n",
    "\n",
    "    # loop over all LCs for the system    \n",
    "    for f in flc[:1]:\n",
    "\n",
    "        # If any planet transiting\n",
    "        if system.shape[0] > 0:\n",
    "\n",
    "            # mask transits\n",
    "            tranmask = get_full_transit_mask(system, f, pad=0)\n",
    "            f.flux[tranmask] = np.nan\n",
    "    \n",
    "        print(f.time, f.time.shape)\n",
    "        plt.plot(f.time, f.flux)\n",
    "        # apply custom detrending\n",
    "        fd = custom_detrending(f, pad=3)\n",
    "        plt.plot(fd.time, fd.flux)\n",
    "\n",
    "        # define two hour window for rolling std\n",
    "#         print(fd.time, np.diff(fd.time))\n",
    "        w = np.floor(1./12./np.nanmin(np.diff(fd.time)))\n",
    "        if w%2==0: \n",
    "            w+=1\n",
    "\n",
    "        # use window to estimate the noise in the LC\n",
    "        df = estimate_detrended_noise(fd, std_window=int(w), mask_pos_outliers_sigma=1.5)\n",
    "\n",
    "        # search the residual for flares\n",
    "        ff = df.find_flares(addtail=True, tailthreshdiff=1.5).flares\n",
    "\n",
    "        # get timestamp for result\n",
    "        tstamp = time.strftime(\"%d_%m_%Y_%H_%M_%S\", time.localtime())\n",
    "\n",
    "        # add meta info to flare table\n",
    "        # if no flares found, add empty row\n",
    "        if ff.shape[0]==0:\n",
    "            ff[\"total_n_valid_data_points\"] = df.detrended_flux.shape[0]\n",
    "            ff[\"ID\"] = row.ID\n",
    "            ff[\"qcs\"] = row.qcs\n",
    "            ff[\"mission\"] = row.mission\n",
    "            ff[\"tstamp\"] = tstamp\n",
    "            ff = ff.append({\"total_n_valid_data_points\":df.detrended_flux.shape[0],\n",
    "                            \"ID\":row.ID,\n",
    "                            \"qcs\" : row.qcs,\n",
    "                            \"mission\":row.mission,\n",
    "                            \"tstamp\":tstamp},\n",
    "                             ignore_index=True)\n",
    "\n",
    "        # otherwise add ID, QCS and mission\n",
    "        else:\n",
    "            ff[\"ID\"] = row.ID\n",
    "            ff[\"qcs\"] = row.qcs\n",
    "            ff[\"mission\"] = row.mission\n",
    "            ff[\"tstamp\"] = tstamp\n",
    "\n",
    "        # add results to file\n",
    "        with open(\"../results/AUmic_flares_ttd15.csv\", \"a\") as file:\n",
    "            ff.to_csv(file, index=False, header=True)\n",
    "\n",
    "    # info\n",
    "    n += 1\n",
    "    print(f\"{n / N * 100.:.1f}%, [{n}/{N}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(f.time, f.flux,zorder=-20, c=\"orange\")\n",
    "plt.xlim(122,124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16,5))\n",
    "# plt.plot(df.time, df.flux,zorder=-20, c=\"orange\")\n",
    "# plt.plot(df.time, df.detrended_flux,zorder=-10, c=\"yellow\")\n",
    "# plt.plot(tu, fl,zorder=-30)\n",
    "# # plt.plot(df.time, df.flux-df.detrended_flux,zorder=-20, c=\"orange\")\n",
    "\n",
    "# m = np.nanmedian(df.detrended_flux )\n",
    "# plt.fill_between(df.time, m + 3*df.detrended_flux_err,\n",
    "#                  m - 3*df.detrended_flux_err, alpha=.7)\n",
    "# plt.xlim(df.time[0], df.time[-1])\n",
    "# # plt.ylim(161400,162500)\n",
    "# # plt.xlim(2102,2105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = df.find_flares().flares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# m = np.nanmedian(df.detrended_flux )\n",
    "# for idx, flare in ff.iterrows():\n",
    "#     df_ = df[flare.istart-280:flare.istop+280]\n",
    "#     plt.figure(figsize=(16,5))\n",
    "#     plt.scatter(df_.time, df_.flux,zorder=-20, c=\"orange\")\n",
    "#     plt.plot(df_.time, df_.detrended_flux,zorder=-10, c=\"yellow\")\n",
    "\n",
    "#     plt.fill_between(df_.time, m + 3*df_.detrended_flux_err,\n",
    "#                      m - 3*df_.detrended_flux_err, alpha=.7)\n",
    "#     plt.xlim(df_.time[0],df_.time[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ff.shape[0]==0:\n",
    "    ff[\"total_n_valid_data_points\"] = df.detrended_flux.shape[0]\n",
    "    ff[\"ID\"] = row.ID\n",
    "    ff[\"qcs\"] = row.qcs\n",
    "    ff[\"mission\"] = row.mission\n",
    "    ff = ff.append({\"total_n_valid_data_points\":df.detrended_flux.shape[0],\n",
    "                    \"ID\":row.ID,\n",
    "               \"qcs\" : row.qcs,\n",
    "               \"mission\":row.mission},\n",
    "              ignore_index=True)\n",
    "else:\n",
    "    ff[\"ID\"] = row.ID\n",
    "    ff[\"qcs\"] = row.qcs\n",
    "    ff[\"mission\"] = row.mission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/flares.csv\", \"a\") as file:\n",
    "    ff.to_csv(file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSTART = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exokepler.disc_facility.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0, tf = f.time[0], f.time[-1]\n",
    "\n",
    "for i, row in system.iterrows():\n",
    "    if (np.isnan(row.pl_orbper)) & (~np.isnan(row.pl_tranmidepoch)):\n",
    "        system.loc[i,\"pl_orbper\"] = (tf - t0) * 1e6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system[[\"pl_orbper\",\"pl_tranmidepoch\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs.transitmask import get_transit_mid_epochs\n",
    "\n",
    "\n",
    "assert (get_transit_mid_epochs(30., 300., 20., 40.) ==\n",
    "        np.array([-270.,   30.,  330.])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(f.time, f.flux)\n",
    "plt.xlim(2139,2139.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flc = from_mast(row.ID, mission=row.mission, c=row.qcs, cadence=\"short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flc = flc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flc.flux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if system.shape[0] > 0:\n",
    "\n",
    "    # mask transits\n",
    "    tranmask = get_full_transit_mask(system, flc, pad=0)\n",
    "    flc.flux[tranmask] = np.nan\n",
    "\n",
    "# apply custom detrending\n",
    "fd = custom_detrending(flc)\n",
    "\n",
    "# define two hour window for rolling std\n",
    "#         print(fd.time, np.diff(fd.time))\n",
    "w = np.floor(1./12./np.nanmin(np.diff(fd.time)))\n",
    "if w%2==0: \n",
    "    w+=1\n",
    "\n",
    "# use window to estimate the noise in the LC\n",
    "df = estimate_detrended_noise(fd, std_window=int(w), mask_pos_outliers_sigma=3.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aumic = pd.read_csv(\"../results/AUMic_flares_pad3.csv\")\n",
    "aumic = aumic.sort_values(\"ampl_rec\",ascending=False)\n",
    "\n",
    "%matplotlib inline\n",
    "for l, row in aumic.iloc[:10].iterrows():\n",
    "    plt.figure(figsize=(17,5))\n",
    "    ts, tf = row.tstart, row.tstop\n",
    "    _ = df[np.where((df.time>=ts-.2) & (df.time<=tf+.2))]\n",
    "    plt.plot(_.time, _.detrended_flux)\n",
    "    plt.fill_between(_.time, _.it_med+_.detrended_flux_err, \n",
    "                     _.it_med-_.detrended_flux_err,alpha=0.7,facecolor=\"orange\")\n",
    "#     plt.plot(flc.time, flc.flux)\n",
    "#     plt.xlim(df.time[0],df.time[-1]);\n",
    "    \n",
    "    plt.xlim(ts - .1, tf + .1)\n",
    "    _ = df[np.where((df.time>=ts) & (df.time<=tf))]\n",
    "    plt.plot(_.time, _.detrended_flux, c=\"r\")\n",
    "#     plt.ylim(277500,280000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aumic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aumic = pd.read_csv(\"../results/AUMic_flares_pad3_sig1_addtail.csv\")\n",
    "aumic = aumic.sort_values(\"ampl_rec\",ascending=True)\n",
    "\n",
    "%matplotlib inline\n",
    "for l, row in aumic.iloc[-10:].iterrows():\n",
    "    plt.figure(figsize=(17,5))\n",
    "    ts, tf = row.tstart, row.tstop\n",
    "    _ = df[np.where((df.time>=ts-.2) & (df.time<=tf+.2))]\n",
    "    plt.plot(_.time, _.detrended_flux)\n",
    "    plt.fill_between(_.time, _.it_med+_.detrended_flux_err, \n",
    "                     _.it_med-_.detrended_flux_err,alpha=0.7,facecolor=\"orange\")\n",
    "#     plt.plot(flc.time, flc.flux)\n",
    "#     plt.xlim(df.time[0],df.time[-1]);\n",
    "    \n",
    "    plt.xlim(ts - .1, tf + .1)\n",
    "    _ = df[np.where((df.time>=ts) & (df.time<=tf))]\n",
    "    plt.plot(_.time, _.detrended_flux, c=\"r\")\n",
    "#     plt.ylim(277500,280000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in list of LCs to search\n",
    "es = pd.read_csv(\"../data/20_01_2021_full_kepler_k2_tess_exoplanet_lcs_some_excluded.csv\")\n",
    "\n",
    "# select only Kepler and TESS, ignore K2 for now\n",
    "eskeptess = es[(es.mission==\"TESS\") | (es.mission==\"Kepler\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "32000/60/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fla[fla.ID==\"16 Cyg B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~eskeptess.ID.isin(fla.ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eskeptess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10 ** np.linspace(-2,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(75)\n",
    "y = 3*np.sqrt(x)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forallpurposes",
   "language": "python",
   "name": "forallpurposes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
